{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Load Data\n",
    "作業に必要なライブラリをインポートして、 以下のデータを読み込みます。\n",
    "\n",
    "* stock_price : 株価情報\n",
    "* stock_list : 銘柄情報\n",
    "* stock_fin : 財務諸表\n",
    "* stock_labels : 目的変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shap用にg++とgccをインストールします\n",
    "! apt-get update\n",
    "! apt-get install -y --no-install-recommends g++ gcc\n",
    "\n",
    "# 必要なライブラリをインストールします\n",
    "! pip install shap==0.37.0 slicer==0.0.3 xgboost==1.3.0.post0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import  xgboost as xgb\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# 表示用の設定を変更します\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.width = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "# python 3.7.3であることを確認します\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット保存先ディレクトリ（\"\"の中身はご自身の環境に合わせて定義してください。）\n",
    "dataset_dir=\"/path/to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_list\n",
      "stock_price\n",
      "stock_fin\n",
      "stock_labels\n"
     ]
    }
   ],
   "source": [
    "# 読み込むファイルを定義します。\n",
    "inputs = {\n",
    "    \"stock_list\": f\"{dataset_dir}/stock_list.csv.gz\",\n",
    "    \"stock_price\": f\"{dataset_dir}/stock_price.csv.gz\",\n",
    "    \"stock_fin\": f\"{dataset_dir}/stock_fin.csv.gz\",\n",
    "    # 本チュートリアルでは使用しないため、コメントアウトしています。\n",
    "    # \"stock_fin_price\": f\"{dataset_dir}/stock_fin_price.csv.gz\",\n",
    "    \"stock_labels\": f\"{dataset_dir}/stock_labels.csv.gz\",\n",
    "}\n",
    "\n",
    "# ファイルを読み込みます\n",
    "dfs = {}\n",
    "for k, v in inputs.items():\n",
    "    print(k)\n",
    "    dfs[k] = pd.read_csv(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT_FIN_DATA_COLUMNS = ['Result_FinancialStatement FiscalYear', 'Result_FinancialStatement NetSales',\n",
    "       'Result_FinancialStatement OperatingIncome', 'Result_FinancialStatement OrdinaryIncome',\n",
    "       'Result_FinancialStatement NetIncome', 'Result_FinancialStatement TotalAssets',\n",
    "       'Result_FinancialStatement NetAssets', 'Result_FinancialStatement CashFlowsFromOperatingActivities',\n",
    "       'Result_FinancialStatement CashFlowsFromFinancingActivities',\n",
    "       'Result_FinancialStatement CashFlowsFromInvestingActivities', 'Forecast_FinancialStatement FiscalYear',\n",
    "       'Forecast_FinancialStatement NetSales', 'Forecast_FinancialStatement OperatingIncome',\n",
    "       'Forecast_FinancialStatement OrdinaryIncome', 'Forecast_FinancialStatement NetIncome',\n",
    "       'Result_Dividend FiscalYear', 'Result_Dividend QuarterlyDividendPerShare',\n",
    "       'Result_Dividend AnnualDividendPerShare', 'Forecast_Dividend FiscalYear',\n",
    "       'Forecast_Dividend QuarterlyDividendPerShare', 'Forecast_Dividend AnnualDividendPerShare',\n",
    "       'IssuedShareEquityQuote IssuedShare','Section/Products', '33 Sector(Code)', '17 Sector(Code)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_products = {\n",
    "    \"First Section (Domestic)\" : 1,\n",
    "    \"JASDAQ(Standard / Domestic)\" :2,\n",
    "    \"Second Section(Domestic)\" :3,\n",
    "    \"Mothers (Domestic)\" : 4,\n",
    "    \"JASDAQ(Growth/Domestic)\" :5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_glossary_of_financial_analysis(row):\n",
    "    operating_profit_margin = 0\n",
    "    ordinary_profit_margin = 0\n",
    "    net_profit_margin = 0\n",
    "    total_asset_turnover = 0\n",
    "    net_sales_growth_rate = 0\n",
    "    ordinary_income_growth_rate = 0\n",
    "    operationg_income_growth_rate = 0\n",
    "    total_assets_growth_rate = 0\n",
    "    net_assets_growth_rate = 0\n",
    "    eps = 0\n",
    "    bps = 0\n",
    "    roe = 0\n",
    "\n",
    "    # 売上高営業利益率 売上高営業利益率（％）＝営業利益÷売上高×100\n",
    "    if row['Result_FinancialStatement NetSales'] != 0:\n",
    "        operating_profit_margin = \\\n",
    "            row['Result_FinancialStatement OperatingIncome'] / \\\n",
    "            row['Result_FinancialStatement NetSales'] * 100\n",
    "    # 売上高経常利益率　売上高経常利益率（％）＝経常利益÷売上高×100\n",
    "    if row['Result_FinancialStatement NetSales'] != 0:\n",
    "        ordinary_profit_margin = \\\n",
    "            row['Result_FinancialStatement OrdinaryIncome'] / \\\n",
    "            row['Result_FinancialStatement NetSales'] * 100\n",
    "    # 売上高純履歴率　売上高純利益率（％）＝当期純利益÷売上高×100\n",
    "    if row['Result_FinancialStatement NetSales'] != 0:\n",
    "        net_profit_margin = row['Result_FinancialStatement NetIncome'] / \\\n",
    "                            row['Result_FinancialStatement NetSales'] * 100\n",
    "    # 総資本回転率 総資本回転率（％）＝売上高÷総資本（自己資本＋他人資本）×100\n",
    "    if row['Result_FinancialStatement NetAssets'] != 0:\n",
    "        total_asset_turnover = row['Result_FinancialStatement NetSales'] / \\\n",
    "                            row['Result_FinancialStatement NetAssets'] * 100\n",
    "    # 売上高増加率\n",
    "    if row['Previous_FinancialStatement NetSales'] != 0:\n",
    "        net_sales_growth_rate = \\\n",
    "            (row['Result_FinancialStatement NetSales'] -\n",
    "            row['Previous_FinancialStatement NetSales']) / \\\n",
    "            row['Previous_FinancialStatement NetSales'] * 100\n",
    "    # 経常利益増加率\n",
    "    if row['Previous_FinancialStatement OrdinaryIncome'] != 0:\n",
    "        ordinary_income_growth_rate = \\\n",
    "            (row['Result_FinancialStatement OrdinaryIncome'] -\n",
    "            row['Previous_FinancialStatement OrdinaryIncome']) / \\\n",
    "            row['Previous_FinancialStatement OrdinaryIncome'] * 100\n",
    "\n",
    "    # 営業利益増加率\n",
    "    if row['Previous_FinancialStatement OperatingIncome'] != 0:\n",
    "        operationg_income_growth_rate = \\\n",
    "            (row['Result_FinancialStatement OperatingIncome'] -\n",
    "            row['Previous_FinancialStatement OperatingIncome']) / \\\n",
    "            row['Previous_FinancialStatement OperatingIncome'] * 100\n",
    "    # 総資本増加率\n",
    "    if row['Previous_FinancialStatement TotalAssets'] != 0:\n",
    "        total_assets_growth_rate = \\\n",
    "            (row['Result_FinancialStatement TotalAssets'] -\n",
    "            row['Previous_FinancialStatement TotalAssets']) / \\\n",
    "            row['Previous_FinancialStatement TotalAssets'] * 100\n",
    "    # 純資本増加率\n",
    "    if row['Previous_FinancialStatement NetAssets'] != 0:\n",
    "        net_assets_growth_rate = \\\n",
    "            (row['Result_FinancialStatement NetAssets'] -\n",
    "            row['Previous_FinancialStatement NetAssets']) / \\\n",
    "            row['Previous_FinancialStatement NetAssets'] * 100\n",
    "    # 一株当たり当期純利益（EPS）\n",
    "    if row['IssuedShareEquityQuote IssuedShare'] != 0:\n",
    "        eps = row['Result_FinancialStatement NetIncome'] / \\\n",
    "            row['IssuedShareEquityQuote IssuedShare']\n",
    "        # BPS 一株当たり純資産（円） ＝ 純資産 ÷ 発行済株式総数\n",
    "        bps = row['Result_FinancialStatement NetAssets'] / \\\n",
    "            row['IssuedShareEquityQuote IssuedShare']\n",
    "        # ROE EPS（一株当たり利益）÷ BPS（一株当たり純資産）× 100\n",
    "        if bps > 0:\n",
    "            roe = eps / bps * 100\n",
    "    return pd.Series(\n",
    "        [operating_profit_margin, ordinary_profit_margin,\n",
    "            net_profit_margin, total_asset_turnover,\n",
    "            net_sales_growth_rate, ordinary_income_growth_rate,\n",
    "            operationg_income_growth_rate, total_assets_growth_rate,\n",
    "            net_assets_growth_rate, eps, bps, roe])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量の生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_END = \"2017-12-31\"\n",
    "VAL_START = \"2018-02-01\"\n",
    "VAL_END = \"2018-12-01\"\n",
    "TEST_START = \"2019-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_for_predict(dfs, code):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dfs (dict)  : dict of pd.DataFrame include stock_fin, stock_price\n",
    "        code (int)  : A local code for a listed company\n",
    "    Returns:\n",
    "        feature DataFrame (pd.DataFrame)\n",
    "    \"\"\"\n",
    "    # おおまかな手順の1つ目\n",
    "    # stock_finデータを読み込み\n",
    "    stock_fin = dfs[\"stock_fin\"].copy()\n",
    "    \n",
    "    stock_list = dfs[\"stock_list\"].copy()\n",
    "    stock_fin = pd.merge(stock_fin, stock_list, on=[\"Local Code\"] )\n",
    "\n",
    "    # 特定の銘柄コードのデータに絞る\n",
    "    fin_data = stock_fin[stock_fin[\"Local Code\"] == code].copy()\n",
    "    # 日付列をpd.Timestamp型に変換してindexに設定\n",
    "    fin_data[\"datetime\"] = pd.to_datetime(fin_data[\"base_date\"])\n",
    "    fin_data.set_index(\"datetime\", inplace=True)\n",
    "    # fin_dataを選択\n",
    "    fin_data = fin_data[SELECT_FIN_DATA_COLUMNS]\n",
    "    fin_data = fin_data.join(fin_data[['Result_FinancialStatement NetSales', 'Result_FinancialStatement OperatingIncome', \n",
    "                                   'Result_FinancialStatement OrdinaryIncome', 'Result_FinancialStatement NetIncome', \n",
    "                                   'Result_FinancialStatement TotalAssets', 'Result_FinancialStatement NetAssets',\n",
    "                                   'Result_FinancialStatement CashFlowsFromOperatingActivities', \n",
    "                                   'Result_FinancialStatement CashFlowsFromFinancingActivities',\n",
    "                                   'Result_FinancialStatement CashFlowsFromInvestingActivities']].rename(columns =\n",
    "                                                                                                         {'Result_FinancialStatement NetSales': 'Previous_FinancialStatement NetSales',\n",
    "                                                                                                          'Result_FinancialStatement OperatingIncome': 'Previous_FinancialStatement OperatingIncome', \n",
    "                                                                                                          'Result_FinancialStatement OrdinaryIncome': 'Previous_FinancialStatement OrdinaryIncome', \n",
    "                                                                                                          'Result_FinancialStatement NetIncome':'Previous_FinancialStatement NetIncome', \n",
    "                                                                                                          'Result_FinancialStatement TotalAssets': 'Previous_FinancialStatement TotalAssets', \n",
    "                                                                                                          'Result_FinancialStatement NetAssets':'Previous_FinancialStatement NetAssets',\n",
    "                                                                                                          'Result_FinancialStatement CashFlowsFromOperatingActivities': 'Previous_FinancialStatement CashFlowsFromOperatingActivities', \n",
    "                                                                                                          'Result_FinancialStatement CashFlowsFromFinancingActivities':'Previous_FinancialStatement CashFlowsFromFinancingActivities',\n",
    "                                                                                                          'Result_FinancialStatement CashFlowsFromInvestingActivities':'Previous_FinancialStatement CashFlowsFromInvestingActivities'}).shift(-1))\n",
    "    fin_data[['operating_profit_margin', 'ordinary_profit_margin', 'net_profit_margin', 'total_asset_turnover',\n",
    "         'net_sales_growth_rate', 'ordinary_income_growth_rate', 'operationg_income_growth_rate',\n",
    "          'total_assets_growth_rate', 'net_assets_growth_rate', 'eps', 'bps', 'roe']] = fin_data.apply(calculate_glossary_of_financial_analysis, axis=1)\n",
    "\n",
    "    # 欠損値処理\n",
    "    fin_feats = fin_data.fillna(0)\n",
    "\n",
    "    # おおまかな手順の2つ目\n",
    "    # stock_priceデータを読み込む\n",
    "    price = dfs[\"stock_price\"].copy()\n",
    "    # 特定の銘柄コードのデータに絞る\n",
    "    price_data = price[price[\"Local Code\"] == code].copy()\n",
    "    # 日付列をpd.Timestamp型に変換してindexに設定\n",
    "    price_data[\"datetime\"] = pd.to_datetime(price_data[\"EndOfDayQuote Date\"])\n",
    "    price_data.set_index(\"datetime\", inplace=True)\n",
    "    # 終値のみに絞る\n",
    "    feats = price_data[[\"EndOfDayQuote ExchangeOfficialClose\"]].copy()\n",
    "    # 終値の20営業日リターン\n",
    "    feats[\"return_1month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(20)\n",
    "    # 終値の40営業日リターン\n",
    "    feats[\"return_2month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(40)\n",
    "    # 終値の60営業日リターン\n",
    "    feats[\"return_3month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(60)\n",
    "    # 終値の20営業日ボラティリティ\n",
    "    feats[\"volatility_1month\"] = (\n",
    "        np.log(feats[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(20).std()\n",
    "    )\n",
    "    # 終値の40営業日ボラティリティ\n",
    "    feats[\"volatility_2month\"] = (\n",
    "        np.log(feats[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(40).std()\n",
    "    )\n",
    "    # 終値の60営業日ボラティリティ\n",
    "    feats[\"volatility_3month\"] = (\n",
    "        np.log(feats[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(60).std()\n",
    "    )\n",
    "    # 終値と20営業日の単純移動平均線の乖離\n",
    "    feats[\"MA_gap_1month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (\n",
    "        feats[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(20).mean()\n",
    "    )\n",
    "    # 終値と40営業日の単純移動平均線の乖離\n",
    "    feats[\"MA_gap_2month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (\n",
    "        feats[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(40).mean()\n",
    "    )\n",
    "    # 終値と60営業日の単純移動平均線の乖離\n",
    "    feats[\"MA_gap_3month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (\n",
    "        feats[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(60).mean()\n",
    "    )\n",
    "    \n",
    "    # EWMA\n",
    "    ALPHA = 0.25\n",
    "    feats[\"EWMA\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"]\n",
    "\n",
    "    for t in zip(feats.index, feats.index[1:]):\n",
    "        feats.loc[t[1], \"EWMA\"] = ALPHA * feats.loc[t[1], \"EndOfDayQuote ExchangeOfficialClose\"] + (1 - ALPHA) * feats.loc[t[0], \"EWMA\"]\n",
    "    \n",
    "    # EMA 10日\n",
    "    feats[\"ema_10\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].ewm(span=10).mean()\n",
    "    \n",
    "    # MACD \n",
    "    # EMA12\n",
    "    feats[\"ema_12\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].ewm(span=12).mean()\n",
    "    # EMA 26\n",
    "    feats[\"ema_26\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].ewm(span=26).mean()\n",
    "    feats[\"macd\"] = feats[\"ema_12\"] - feats[\"ema_26\"]\n",
    "    feats[\"signal\"] = feats[\"macd\"].ewm(span=9).mean()\n",
    "    \n",
    "    # PBR 株価 ÷ BPS（1株あたり純資産）\n",
    "    feats[\"pbr\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / fin_data[\"bps\"]\n",
    "    # PER 株価 ÷ 1株当たり利益（EPS）\n",
    "    feats[\"per\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / fin_data[\"eps\"]\n",
    "\n",
    "    # おおまかな手順の3つ目\n",
    "    # 欠損値処理\n",
    "    feats = feats.fillna(0)\n",
    "    # 元データのカラムを削除\n",
    "    feats = feats.drop([\"EndOfDayQuote ExchangeOfficialClose\"], axis=1)\n",
    "\n",
    "    # 財務データの特徴量とマーケットデータの特徴量のインデックスを合わせる\n",
    "    feats = feats.loc[feats.index.isin(fin_feats.index)]\n",
    "    fin_feats = fin_feats.loc[fin_feats.index.isin(feats.index)]\n",
    "\n",
    "    # データを結合\n",
    "    feats = pd.concat([feats, fin_feats], axis=1).dropna()\n",
    "\n",
    "    # 欠損値処理を行います。\n",
    "    feats = feats.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    # 市場・商品区分を数値に変換\n",
    "    feats[\"Section/Products\"] = section_products[feats[\"Section/Products\"][0]]\n",
    "    # 銘柄コードを設定\n",
    "    feats[\"code\"] = code\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_label(dfs, codes, feature, label):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dfs (dict[pd.DataFrame]): loaded data\n",
    "        codes  (array) : target codes\n",
    "        feature (pd.DataFrame): features\n",
    "        label (str) : label column name\n",
    "    Returns:\n",
    "        train_X (pd.DataFrame): training data\n",
    "        train_y (pd.DataFrame): label for train_X\n",
    "        val_X (pd.DataFrame): validation data\n",
    "        val_y (pd.DataFrame): label for val_X\n",
    "        test_X (pd.DataFrame): test data\n",
    "        test_y (pd.DataFrame): label for test_X\n",
    "    \"\"\"\n",
    "    # 分割データ用の変数を定義\n",
    "    trains_X, vals_X, tests_X = [], [], []\n",
    "    trains_y, vals_y, tests_y = [], [], []\n",
    "\n",
    "    # 銘柄コード毎に特徴量を作成\n",
    "    for code in tqdm(codes):\n",
    "        # 特徴量取得\n",
    "        feats = feature[feature[\"code\"] == code]\n",
    "\n",
    "        # stock_labelデータを読み込み\n",
    "        stock_labels = dfs[\"stock_labels\"].copy()\n",
    "        # 特定の銘柄コードのデータに絞る\n",
    "        stock_labels = stock_labels[stock_labels[\"Local Code\"] == code]\n",
    "        # 日付列をpd.Timestamp型に変換してindexに設定\n",
    "        stock_labels[\"datetime\"] = pd.to_datetime(stock_labels[\"base_date\"])\n",
    "        stock_labels.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "        # 特定の目的変数に絞る\n",
    "        labels = stock_labels[label]\n",
    "        # nanを削除\n",
    "        labels.dropna(inplace=True)\n",
    "\n",
    "        if feats.shape[0] > 0 and labels.shape[0] > 0:\n",
    "            # 特徴量と目的変数のインデックスを合わせる\n",
    "            labels = labels.loc[labels.index.isin(feats.index)]\n",
    "            feats = feats.loc[feats.index.isin(labels.index)]\n",
    "            labels.index = feats.index\n",
    "\n",
    "            # データを分割（ホールドアウト法）\n",
    "            _train_X = feats[: TRAIN_END].copy()\n",
    "            _val_X = feats[VAL_START : VAL_END].copy()\n",
    "            _test_X = feats[TEST_START :].copy()\n",
    "\n",
    "            _train_y = labels[: TRAIN_END].copy()\n",
    "            _val_y = labels[VAL_START : VAL_END].copy()\n",
    "            _test_y = labels[TEST_START :].copy()\n",
    "\n",
    "            # データを配列に格納 (後ほど結合するため)\n",
    "            trains_X.append(_train_X)\n",
    "            vals_X.append(_val_X)\n",
    "            tests_X.append(_test_X)\n",
    "\n",
    "            trains_y.append(_train_y)\n",
    "            vals_y.append(_val_y)\n",
    "            tests_y.append(_test_y)\n",
    "\n",
    "    # 銘柄毎に作成した説明変数データを結合します。\n",
    "    train_X = pd.concat(trains_X)\n",
    "    val_X = pd.concat(vals_X)\n",
    "    test_X = pd.concat(tests_X)\n",
    "    # 銘柄毎に作成した目的変数データを結合します。\n",
    "    train_y = pd.concat(trains_y)\n",
    "    val_y = pd.concat(vals_y)\n",
    "    test_y = pd.concat(tests_y)\n",
    "\n",
    "    return train_X, train_y, val_X, val_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codes(dfs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dfs (dict[pd.DataFrame]): loaded data\n",
    "    Returns:\n",
    "        array: list of stock codes\n",
    "    \"\"\"\n",
    "    stock_list = dfs[\"stock_list\"].copy()\n",
    "    # 予測対象の銘柄コードを取得\n",
    "    codes = stock_list[stock_list[\"prediction_target\"] == True][\n",
    "        \"Local Code\"\n",
    "    ].values\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_columns(dfs, train_X, column_group=\"fundamental+technical\"):\n",
    "    # 特徴量グループを定義\n",
    "    # ファンダメンタル\n",
    "    fundamental_cols = dfs[\"stock_fin\"].select_dtypes(\"float64\").columns\n",
    "    fundamental_cols = fundamental_cols[\n",
    "        fundamental_cols != \"Result_Dividend DividendPayableDate\"\n",
    "        ]\n",
    "    fundamental_cols = fundamental_cols[fundamental_cols != \"Local Code\"]\n",
    "    # 価格変化率\n",
    "    returns_cols = [x for x in train_X.columns if \"return\" in x]\n",
    "    # テクニカル\n",
    "    technical_cols = [\n",
    "        x for x in train_X.columns if\n",
    "        (x not in fundamental_cols) and (x != \"code\")\n",
    "    ]\n",
    "    columns = {\n",
    "        \"fundamental_only\": fundamental_cols,\n",
    "        \"return_only\": returns_cols,\n",
    "        \"technical_only\": technical_cols,\n",
    "        \"fundamental+technical\": list(fundamental_cols) + list(\n",
    "            technical_cols),\n",
    "    }\n",
    "    return columns[column_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.path.dirname(\"__file__\"), \"../model\")\n",
    "test_X_path = os.path.join(os.path.dirname(\"__file__\"), \"../model/proceed_datas/test_X\")\n",
    "test_y_path = os.path.join(os.path.dirname(\"__file__\"), \"../model/proceed_datas/test_y\")\n",
    "val_X_path = os.path.join(os.path.dirname(\"__file__\"), \"../model/proceed_datas/val_X\")\n",
    "val_y_path = os.path.join(os.path.dirname(\"__file__\"), \"../model/proceed_datas/val_y\")\n",
    "train_X_path = os.path.join(os.path.dirname(\"__file__\"), \"../model/proceed_datas/train_X\")\n",
    "train_y_path = os.path.join(os.path.dirname(\"__file__\"), \"../model/proceed_datas/train_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対象の目的変数を定義\n",
    "labels = {\n",
    "labels = {\n",
    "    \"label_high_5\",\n",
    "    \"label_high_10\",\n",
    "    \"label_high_20\",\n",
    "    \"label_low_5\",\n",
    "    \"label_low_10\",\n",
    "    \"label_low_20\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量追加済みデータ\n",
    "proceed_datas = {\n",
    "    \"train_X\",\n",
    "    \"train_y\",\n",
    "    \"val_X\",\n",
    "    \"val_y\",\n",
    "    \"test_X\",\n",
    "    \"test_y\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "フォ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(train_X_path, \"train_X_label_high_5.pkl\"), \"rb\") as f:\n",
    "    train_X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_path, \"test_X\"), \"rb\") as f:\n",
    "    test_X = pickle.load(f)\n",
    "    proceed_models[\"test_X\"] = test_X\n",
    "with open(os.path.join(model_path, \"test_y\"), \"rb\") as f:\n",
    "    test_y = pickle.load(f)\n",
    "    proceed_models[\"test_y\"] = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_path, \"train_X\"), \"rb\") as f:\n",
    "    train_X = pickle.load(f)\n",
    "    proceed_models[\"train_X\"] = train_X\n",
    "with open(os.path.join(model_path, \"train_y\"), \"rb\") as f:\n",
    "    train_y = pickle.load(f)\n",
    "    proceed_models[\"train_y\"] = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_path, \"val_X\"), \"rb\") as f:\n",
    "    val_X = pickle.load(f)\n",
    "    proceed_models[\"val_X\"] = val_X\n",
    "with open(os.path.join(model_path, \"val_y\"), \"rb\") as f:\n",
    "    val_y = pickle.load(f)\n",
    "    proceed_models[\"val_y\"] = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "reg_cv = GridSearchCV(xgb, {\n",
    "    \"eta\": [0.01, 0.05, 0.1], \n",
    "    \"gamma\": [0.1,0.2,0.3,0.4,0.5],\n",
    "    \"n_estimators\": [50, 100, 200], \n",
    "    \"max_depth\": [5, 7, 9,10,20,30],\n",
    "    \"subsample\":[0.6,0.8,1],\n",
    "    \"colsample_bytree\": [0.5,0.7,0.9],\n",
    "}, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "        with open(os.path.join(model_path, f\"my_model_{label}.pkl\"), \"wb\") as f:\n",
    "        # モデルをpickle形式で保存\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['return_1month', 'return_2month', 'return_3month', 'volatility_1month', 'volatility_2month',\n",
       "       'volatility_3month', 'MA_gap_1month', 'MA_gap_2month', 'MA_gap_3month', 'EWMA', 'ema_10', 'ema_12', 'ema_26',\n",
       "       'macd', 'signal', 'pbr', 'per', 'Result_FinancialStatement FiscalYear', 'Result_FinancialStatement NetSales',\n",
       "       'Result_FinancialStatement OperatingIncome', 'Result_FinancialStatement OrdinaryIncome',\n",
       "       'Result_FinancialStatement NetIncome', 'Result_FinancialStatement TotalAssets',\n",
       "       'Result_FinancialStatement NetAssets', 'Result_FinancialStatement CashFlowsFromOperatingActivities',\n",
       "       'Result_FinancialStatement CashFlowsFromFinancingActivities',\n",
       "       'Result_FinancialStatement CashFlowsFromInvestingActivities', 'Forecast_FinancialStatement FiscalYear',\n",
       "       'Forecast_FinancialStatement NetSales', 'Forecast_FinancialStatement OperatingIncome',\n",
       "       'Forecast_FinancialStatement OrdinaryIncome', 'Forecast_FinancialStatement NetIncome',\n",
       "       'Result_Dividend FiscalYear', 'Result_Dividend QuarterlyDividendPerShare',\n",
       "       'Result_Dividend AnnualDividendPerShare', 'Forecast_Dividend FiscalYear',\n",
       "       'Forecast_Dividend QuarterlyDividendPerShare', 'Forecast_Dividend AnnualDividendPerShare',\n",
       "       'IssuedShareEquityQuote IssuedShare', 'Section/Products', '33 Sector(Code)', '17 Sector(Code)',\n",
       "       'Previous_FinancialStatement NetSales', 'Previous_FinancialStatement OperatingIncome',\n",
       "       'Previous_FinancialStatement OrdinaryIncome', 'Previous_FinancialStatement NetIncome',\n",
       "       'Previous_FinancialStatement TotalAssets', 'Previous_FinancialStatement NetAssets',\n",
       "       'Previous_FinancialStatement CashFlowsFromOperatingActivities',\n",
       "       'Previous_FinancialStatement CashFlowsFromFinancingActivities',\n",
       "       'Previous_FinancialStatement CashFlowsFromInvestingActivities', 'operating_profit_margin',\n",
       "       'ordinary_profit_margin', 'net_profit_margin', 'total_asset_turnover', 'net_sales_growth_rate',\n",
       "       'ordinary_income_growth_rate', 'operationg_income_growth_rate', 'total_assets_growth_rate',\n",
       "       'net_assets_growth_rate', 'eps', 'bps', 'roe', 'code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['label_high_5'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ef8585756cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_feature_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fundamental_only'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-387387a6e56d>\u001b[0m in \u001b[0;36mget_feature_columns\u001b[0;34m(dfs, train_X, column_group)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfundamental_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfundamental_cols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfundamental_cols\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Local Code\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# 価格変化率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mreturns_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"return\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m# テクニカル\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     technical_cols = [\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "feature_columns = get_feature_columns(dfs, train_X, column_group='fundamental_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ライブラリインポート\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# モデル定義\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "# ハイパーパラメータ探索\n",
    "reg_cv = GridSearchCV(model, {\n",
    "    \"eta\": [0.01, 0.05, 0.1], \n",
    "    \"gamma\": [0.4,0.5],\n",
    "    \"n_estimators\": [50], \n",
    "    \"max_depth\": [5, 7, 9, 10],\n",
    "    \"subsample\":[1],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "    \"random_state\":[0]\n",
    "}, verbose=1)\n",
    "\n",
    "# 訓練実施\n",
    "reg_cv.fit(train_X[label][columns[col]].values, train_y[label].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果を表示\n",
    "print(reg_cv.best_params_)\n",
    "print(reg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = reg_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数を指定\n",
    "label = \"label_high_20\"\n",
    "\n",
    "# 学習用データセット定義\n",
    "# ファンダメンタル情報\n",
    "#fundamental_cols = dfs[\"stock_fin\"].select_dtypes(\"float64\").columns\n",
    "fundamental_cols = pd.Index(SELECT_FIN_DATA_COLUMNS)\n",
    "fundamental_cols = fundamental_cols[fundamental_cols != \"Result_Dividend DividendPayableDate\"]\n",
    "fundamental_cols = fundamental_cols[fundamental_cols != \"Local Code\"]\n",
    "# 価格変化率\n",
    "returns_cols = [x for x in train_X[label].columns if \"return\" in x]\n",
    "# テクニカル\n",
    "technical_cols = [x for x in train_X[label].columns if (x not in fundamental_cols) and (x != \"code\")]\n",
    "\n",
    "columns = {\n",
    "    \"fundamental_only\": fundamental_cols,\n",
    "    \"return_only\": returns_cols,\n",
    "    \"technical_only\": technical_cols,\n",
    "    \"fundamental+technical\": list(fundamental_cols) + list(technical_cols),\n",
    "}\n",
    "# 学習用データセットを指定\n",
    "col = \"fundamental+technical\"\n",
    "\n",
    "# 学習\n",
    "#pred_model = models[model](reg_cv.best_estimator_, random_state=0)\n",
    "best_model.fit(train_X[label][columns[col]].values, train_y[label].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用データセット定義\n",
    "columns = {\n",
    "    \"fundamental_only\": fundamental_cols,\n",
    "    \"return_only\": returns_cols,\n",
    "    \"technical_only\": technical_cols,\n",
    "    \"fundamental+technical\": list(fundamental_cols) + list(technical_cols),\n",
    "}\n",
    "\n",
    "# 結果保存用\n",
    "all_results = dict()\n",
    "all_results['XGB'] = dict()\n",
    "# データセット毎に処理\n",
    "for col in columns.keys():\n",
    "    result = dict()\n",
    "    # 目的変数毎に処理\n",
    "    for label in tqdm(labels):\n",
    "        if len(test_X[label][columns[col]]) > 0:\n",
    "            # モデル取得\n",
    "            pred_model = best_model\n",
    "            # 学習\n",
    "            pred_model.fit(train_X[label][columns[col]].values, train_y[label])\n",
    "            # 結果データ作成\n",
    "            result[label] = test_X[label][[\"code\"]].copy()\n",
    "            result[label][\"datetime\"] = test_X[label][columns[col]].index\n",
    "            # 予測\n",
    "            result[label][\"predict\"] = pred_model.predict(test_X[label][columns[col]].values)\n",
    "            result[label][\"predict_dir\"] = np.sign(result[label][\"predict\"])\n",
    "            # 実際の結果\n",
    "            result[label][\"actual\"] = test_y[label].values\n",
    "            result[label][\"actual_dir\"] = np.sign(result[label][\"actual\"])\n",
    "            result[label].dropna(inplace=True)\n",
    "\n",
    "    all_results['XGB'][col] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for model in all_results.keys():\n",
    "    for col in all_results[model]:\n",
    "        tmp = pd.concat(all_results[model][col])\n",
    "        tmp[\"model\"] = model\n",
    "        tmp[\"feature\"] = col\n",
    "        results.append(tmp)\n",
    "results = pd.concat(results)\n",
    "results[\"label\"] = [x[0] for x in results.index]\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果保存用変数\n",
    "all_metrics = []\n",
    "\n",
    "# データセット毎に処理\n",
    "for feature in columns:\n",
    "    matrix = dict()\n",
    "    # 目的変数毎に処理\n",
    "    for label in labels:\n",
    "        # 処理対象データに絞り込み\n",
    "        tmp_df = results[(results[\"model\"] == \"XGB\") & (results[\"label\"] == label) & (results[\"feature\"] == feature)]\n",
    "        # RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(tmp_df[\"predict\"], tmp_df[\"actual\"]))\n",
    "        # 精度\n",
    "        accuracy = accuracy_score(tmp_df[\"predict_dir\"], tmp_df[\"actual_dir\"])\n",
    "        # 相関係数\n",
    "        corr = np.corrcoef(tmp_df[\"actual\"], tmp_df[\"predict\"])[0, 1]\n",
    "        # 順位相関\n",
    "        spearman_corr = spearmanr(tmp_df[\"actual\"], tmp_df[\"predict\"])[0]\n",
    "        # 結果を保存\n",
    "        matrix[label] = [rmse, accuracy, spearman_corr,corr, corr**2, feature, model, tmp_df.shape[0]]\n",
    "    res = pd.DataFrame.from_dict(matrix).T\n",
    "    res.columns = [\"RMSE\",\"accuracy\",\"spearman_corr\",\"corr\",\"R^2 score\",\"feature\", \"model\", \"# of samples\"]\n",
    "    all_metrics.append(res)\n",
    "all_metrics = pd.concat(all_metrics)\n",
    "all_metrics.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = all_metrics.drop(columns=[\"# of samples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp.to_csv('result_XGB.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('result_XGB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.groupby(['feature', 'model']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
